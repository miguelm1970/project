{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Google Colab specific library for mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Machine Learning and Model Evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Recommendation system libraries\n",
        "from surprise import SVD, accuracy, Reader, Dataset\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import auc_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIjlrnaG43-t",
        "outputId": "9490c0bd-64dd-4cf1-88c6-7ba7cc064b88"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset"
      ],
      "metadata": {
        "id": "gcfaCzbj4x8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "data = pd.read_csv('/content/drive/My Drive/activity_train.csv')\n",
        "data.iloc[:, 1] = data.iloc[:, 1].str.strip()\n",
        "print(\"\\n=========================================\")\n",
        "print(\"1. Data Information (TRAIN)\")\n",
        "print(\"=========================================\\n\")\n",
        "print(data.head())\n",
        "print(\"\\n\")\n",
        "print(data.describe())\n",
        "print(\"\\n\")\n",
        "print(data.info())\n",
        "\n",
        "# read test data\n",
        "data_test = pd.read_csv('/content/drive/My Drive/activity_test_blanked.csv')\n",
        "print(\"\\n=========================================\")\n",
        "print(\"2. Data Information (TEST)\")\n",
        "print(\"=========================================\\n\")\n",
        "print(data_test.head())\n",
        "\n",
        "# shows some fingerprints\n",
        "print(\"\\n=========================================\")\n",
        "print(\"3. Fingerprints\")\n",
        "print(\"=========================================\\n\")\n",
        "\n",
        "# get fingerprints\n",
        "# in pickle : dictionary with keys corresponding the ChEMBL IDs and values corresponding to a list of the set bits of each molecule.\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/mol_bits.pkl', 'rb') as f:\n",
        "    fingerprint = pickle.load(f)\n",
        "\n",
        "for key in list(fingerprint.keys())[:5]:\n",
        "    print(key, fingerprint[key])\n",
        "\n",
        "# size of fingerprints\n",
        "print(\" Number of fingerprints: \", len(fingerprint))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbHqv1th4tkU",
        "outputId": "f71ecb8c-4f68-438b-9255-3c122b6417de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=========================================\n",
            "1. Data Information (TRAIN)\n",
            "=========================================\n",
            "\n",
            "   O14842  CHEMBL2022243   4\n",
            "0  O14842  CHEMBL2022244   6\n",
            "1  O14842  CHEMBL2022245   2\n",
            "2  O14842  CHEMBL2022246   1\n",
            "3  O14842  CHEMBL2022247   4\n",
            "4  O14842  CHEMBL2022248   4\n",
            "\n",
            "\n",
            "                   4\n",
            "count  135710.000000\n",
            "mean        4.708798\n",
            "std         2.869917\n",
            "min         1.000000\n",
            "25%         2.000000\n",
            "50%         5.000000\n",
            "75%         7.000000\n",
            "max        10.000000\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135710 entries, 0 to 135709\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   O14842          135710 non-null  object\n",
            " 1    CHEMBL2022243  135710 non-null  object\n",
            " 2    4              135710 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 3.1+ MB\n",
            "None\n",
            "\n",
            "=========================================\n",
            "2. Data Information (TEST)\n",
            "=========================================\n",
            "\n",
            "   O14842   CHEMBL2022258  0\n",
            "0  O14842   CHEMBL2047161  0\n",
            "1  O14842   CHEMBL2047163  0\n",
            "2  O14842   CHEMBL2047168  0\n",
            "3  O14842   CHEMBL2047169  0\n",
            "4  O14842   CHEMBL2048621  0\n",
            "\n",
            "=========================================\n",
            "3. Fingerprints\n",
            "=========================================\n",
            "\n",
            "CHEMBL2022243 [10, 38, 50, 80, 107, 113, 180, 217, 315, 322, 365, 366, 389, 400, 545, 602, 650, 654, 679, 695, 713, 718, 736, 745, 797, 799, 807, 850, 875, 926, 935, 1004, 1019, 1027, 1035, 1039, 1050, 1057, 1066, 1088, 1118, 1121, 1160, 1171, 1173, 1179, 1236, 1237, 1325, 1380, 1391, 1419, 1442, 1452, 1456, 1476, 1501, 1611, 1660, 1722, 1737, 1738, 1746, 1747, 1750, 1754, 1758, 1799, 1873, 1917, 1999, 2021]\n",
            "CHEMBL2022244 [10, 38, 50, 80, 107, 113, 180, 217, 315, 322, 365, 366, 389, 400, 473, 545, 556, 602, 650, 654, 695, 718, 736, 745, 778, 799, 807, 850, 875, 926, 935, 1004, 1019, 1027, 1028, 1035, 1039, 1050, 1057, 1066, 1088, 1112, 1118, 1160, 1171, 1173, 1179, 1236, 1237, 1325, 1380, 1391, 1417, 1419, 1452, 1456, 1460, 1476, 1501, 1544, 1611, 1660, 1722, 1737, 1738, 1746, 1747, 1750, 1754, 1799, 1863, 1873, 1917, 1999, 2021]\n",
            "CHEMBL2022245 [10, 38, 50, 80, 104, 107, 113, 180, 184, 217, 310, 315, 322, 365, 366, 389, 400, 545, 556, 602, 650, 654, 695, 718, 736, 745, 799, 807, 850, 875, 890, 926, 935, 1004, 1019, 1027, 1028, 1035, 1039, 1050, 1057, 1066, 1088, 1112, 1118, 1160, 1171, 1173, 1179, 1236, 1237, 1325, 1380, 1391, 1419, 1452, 1456, 1476, 1501, 1544, 1599, 1611, 1660, 1722, 1737, 1738, 1746, 1747, 1750, 1754, 1799, 1863, 1873, 1917, 1981, 1999, 2021]\n",
            "CHEMBL2022246 [10, 38, 50, 80, 107, 113, 118, 123, 217, 315, 322, 325, 366, 384, 389, 465, 488, 545, 550, 650, 654, 656, 695, 718, 736, 745, 807, 816, 850, 875, 914, 1035, 1039, 1057, 1066, 1088, 1141, 1160, 1171, 1173, 1174, 1179, 1233, 1237, 1269, 1275, 1349, 1357, 1380, 1391, 1419, 1452, 1501, 1503, 1580, 1674, 1722, 1733, 1737, 1747, 1750, 1754, 1799, 1803, 1808, 1873, 1896, 1917, 1999, 2021, 2041]\n",
            "CHEMBL2022247 [10, 22, 38, 50, 66, 80, 107, 113, 160, 180, 217, 315, 322, 366, 389, 441, 491, 545, 640, 650, 654, 656, 695, 718, 736, 745, 807, 850, 875, 926, 946, 1004, 1010, 1019, 1027, 1035, 1039, 1050, 1057, 1066, 1088, 1116, 1160, 1171, 1173, 1179, 1237, 1346, 1380, 1391, 1419, 1452, 1501, 1502, 1509, 1611, 1689, 1722, 1737, 1746, 1747, 1750, 1754, 1799, 1867, 1873, 1887, 1905, 1917, 1923, 1999, 2021]\n",
            " Number of fingerprints:  73865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(activity_table[\"Count\"], labels=activity_table[\"Activity\"], autopct='%1.1f%%', startangle=90)\n",
        "plt.title(\"Count of Each Activity Level\")\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(protein_interactions, bins=30, kde=True)\n",
        "plt.title(\"Number of Interactions per Protein\")\n",
        "plt.xlabel(\"Number of Interactions\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CJ5M_7_LDo4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "FbnqZAIK5i-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of unique fingerprint values\n",
        "fingerprint_values = [f for sublist in fingerprint.values() for f in sublist]\n",
        "fingerprint_values = list(set(fingerprint_values))\n",
        "\n",
        "# Map fingerprint values to indices\n",
        "fingerprint_value_to_index = {value: index for index, value in enumerate(fingerprint_values)}\n",
        "\n",
        "# Assuming 'molecules' is a list of molecule identifiers\n",
        "molecules = list(fingerprint.keys())\n",
        "\n",
        "# Initialize the matrix Y\n",
        "Y = np.zeros((len(molecules), len(fingerprint_values)))\n",
        "\n",
        "# Iterate over all molecules and their fingerprints\n",
        "for mol_idx, mol in enumerate(molecules):\n",
        "    for f in fingerprint[mol]:\n",
        "        # Use the dictionary to find the index of the fingerprint value\n",
        "        Y[mol_idx, fingerprint_value_to_index[f]] = 1\n",
        "# transform the matrix Y to a dataframe\n",
        "Y = pd.DataFrame(Y)\n",
        "Y.columns = fingerprint_values\n",
        "Y.index = molecules\n",
        "\n",
        "# PCA on Y to reduce the dimensionality of the matrix Y\n",
        "pca = PCA(n_components=1000)         # <- 0.86% of the variance is preserved\n",
        "Y_pca = pca.fit_transform(Y)\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_.sum())\n",
        "\n",
        "# plot the explained variance ratio\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "plt.show()\n",
        "\n",
        "# plot the 2d PCA\n",
        "plt.scatter(Y_pca[:, 0], Y_pca[:, 1], alpha=0.5)\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('2D PCA of Y')\n",
        "plt.show()\n",
        "\n",
        "# convert pca to a dataframe with respect molecule name\n",
        "Y_pca = pd.DataFrame(Y_pca)\n",
        "Y_pca.index = molecules\n",
        "\n",
        "# save Y_pca\n",
        "# np.save('Y_pca.npy', Y_pca)"
      ],
      "metadata": {
        "id": "Kb1LoRsKEbtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias Baseline"
      ],
      "metadata": {
        "id": "jAenkhsu4q3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(1, 10))  # escala de classificação de 1 a 10\n",
        "\n",
        "# Divide into train, validation, and test sets\n",
        "X_train, X_test = train_test_split(data, test_size=0.2, random_state=42)\n",
        "X_train, X_val = train_test_split(X_train, test_size=0.25, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "# Tranform train into a Surprise dataset\n",
        "train_data = DatasetAutoFolds(reader=reader, df=X_train)\n",
        "trainset = train_data.build_full_trainset()\n",
        "\n",
        "# Define a grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'n_epochs': [20, 40, 60],\n",
        "    'lr_all': [0.001, 0.005, 0.01],\n",
        "    'reg_all': [0.02, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "gs.fit(train_data)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = gs.best_params['rmse']\n",
        "best_rmse = gs.best_score['rmse']\n",
        "\n",
        "print(f\"Melhores hiperparâmetros: {best_params}\")\n",
        "\n",
        "# Train a new model with the best parameters\n",
        "best_model = SVD(**best_params)\n",
        "best_model.fit(trainset)\n",
        "\n",
        "# Test the model on the validation set\n",
        "predictions = best_model.test(X_val)\n",
        "\n",
        "# Calculate RMSE and MAE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "mae = accuracy.mae(predictions)\n",
        "\n",
        "# Print the results\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"MAE: {mae}\")\n",
        "predictions[:10]"
      ],
      "metadata": {
        "id": "qppK6pPU4ia-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee309f1-46f4-459c-faf8-88745405b582"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightFM Hybrid Recommenders"
      ],
      "metadata": {
        "id": "GI-FP1cx4jSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter common molecules\n",
        "molecules = set(fingerprint.keys())\n",
        "molecules_d = set(data.iloc[:, 1].unique())\n",
        "common_molecules = molecules & molecules_d\n",
        "\n",
        "# Filter and process PCA data\n",
        "Y_pca = Y_pca[[mol in common_molecules for mol in molecules]]\n",
        "Y_pca_df = pd.DataFrame(Y_pca, columns=[f'PC{i+1}' for i in range(Y_pca.shape[1])])\n",
        "\n",
        "# Split data\n",
        "train, test = train_test_split(data.values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare dataset\n",
        "dataset = Dataset()\n",
        "dataset.fit((x[0] for x in data.values), (x[1] for x in data.values), item_features=set(Y_pca_df.columns))\n",
        "\n",
        "# Build interactions and weights matrix\n",
        "train_interactions, _ = dataset.build_interactions((tuple(i) for i in train))\n",
        "test_interactions, _ = dataset.build_interactions((tuple(i) for i in test))\n",
        "\n",
        "# Train model\n",
        "model = LightFM(learning_rate=0.05, loss='warp')\n",
        "model.fit(train_interactions, item_features=sp.csr_matrix(Y_pca_df.values), epochs=20, num_threads=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_auc = auc_score(model, test_interactions, item_features=sp.csr_matrix(Y_pca_df.values)).mean()\n",
        "print(f'Test AUC: {test_auc}')"
      ],
      "metadata": {
        "id": "Ndlt-aG73-1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Activity_test_blanked"
      ],
      "metadata": {
        "id": "IJeo5Beq4O6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with all activity values set to zero\n",
        "data_activity = pd.read_csv('activity_test_blanked.csv')\n",
        "\n",
        "# Prepare the dataset for Surprise\n",
        "data_for_prediction = Dataset.load_from_df(data_activity, reader)\n",
        "testset_for_prediction = data_for_prediction.build_full_trainset().build_testset()\n",
        "\n",
        "# Make predictions on the dataset with zero activity values\n",
        "predictions = best_model.test(testset_for_prediction)\n",
        "\n",
        "# Extract user IDs, item IDs, and predicted ratings from the predictions\n",
        "user_ids = [pred.uid for pred in predictions]\n",
        "item_ids = [pred.iid for pred in predictions]\n",
        "predicted_ratings = [round(pred.est) for pred in predictions]\n",
        "\n",
        "# Create a DataFrame with the predicted ratings\n",
        "predicted_activity = pd.DataFrame({'User': user_ids, 'Item': item_ids, 'Predicted Rating': predicted_ratings})\n",
        "\n",
        "# Save the predicted activity to a CSV file\n",
        "predicted_activity.to_csv('PD_PREDS-04.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "Nau9D6SU33tN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}